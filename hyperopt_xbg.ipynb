{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with imbalanced classes. \n",
    "\n",
    "* using a combination of **hyperopt** and the **XGBoost-Classifier**. To see my experiments with a Neural Network Autoencoder click here. \n",
    "\n",
    "\n",
    "* Using the Kaggle **Credit Card Fraud Detection** dataset. \n",
    "\n",
    "\n",
    "* Quoting from Kaggle: \n",
    "\n",
    "    - The datasets contains transactions made by credit cards in September 2013 by european cardholders.This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "    \n",
    "    - Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n",
    "    \n",
    "    - Features V1-V28 are anonymized. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount.\n",
    "    \n",
    "    \n",
    "* XGBoost \n",
    "\n",
    "    - is known for its excellent speed & performance (operations parallizable) on a variety on Machine Learning problems. \n",
    "    - Is an Ensemble algoritm. It uses CART decision trees as base learners. \n",
    "    \n",
    "    - It is preferred for use when we have a large number of training samples. Number of training samples must be greater than the number of features. \n",
    "    \n",
    "    - The complete parameter list can be found at https://github.com/dmlc/xgboost/blob/master/doc/parameter.rst\n",
    "    \n",
    "    \n",
    "* Hyperopt\n",
    "\n",
    "    - Manual search, grid search and random search are common algorithms used for hyperparameter tuning. \n",
    "    - All these previous methods are un-informed: ie. they scan through the entire/randomly selected set of hyperparameters to select the best one. \n",
    "    - Hyperopt is a Bayasian optimization algorithm, it is classified as an 'informed search' algorithm as the score from the previous round of search, 'informs' the choice of a better set of hyperparameters. \n",
    " \n",
    "* Another extremely cool advantage of hyperopt is: \n",
    "    - There are a lot of machine learning algorithms. And many different configuration for preprocessing/ feature engineering. Hyperopt allows us to use an algorithm to search this large set of other algorithms for the best, without additional input on our part. \n",
    "    - The 'algo' parameter is customizable. I will only use the inbuilt tpe.suggest algo. It is known to work well for most use cases. \n",
    "    - My dataset does not need much pre-processing. \n",
    "    - So I will only try out hyperparameter tuning for XGBoost today. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly_express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style='ticks')\n",
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.max_rows = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 30 feature columns in dataset. \n",
    "    - We don't know what V1-V26 are, but we know they have been scaled (boxplots show a similar range of values, to confirm).\n",
    "    - Additionally,  'Time' in seconds, over a period of 2 days, is available. \n",
    "    - Majority of transactions are of a smaller 'Amount', mean is USD 88, range is ~ USD 0 - USD 25,691 range.\n",
    "    \n",
    "    \n",
    "* No null values in dataset. \n",
    "\n",
    "\n",
    "* Imbalanced classes can be seen below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target contains imbalanced classes\n",
    "data.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot of variables V1 - V28\n",
    "plt.figure(figsize=(20,5))\n",
    "sns.boxplot(data=data.drop(['Time', 'Amount', 'Class'], axis=1))\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Boxplots of features V1 - V26')\n",
    "plt.xlabel('Feature Name')\n",
    "plt.ylabel('Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datelist=pd.date_range(\"00:00:00\", \"23:59:59\", freq=\"S\")\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(20,5))\n",
    "ax1.scatter(data.index, data['Time']/(60*60))\n",
    "ax1.set_xlabel('Index')\n",
    "ax1.set_ylabel('Time feature (in hours)')\n",
    "ax1.set_title('Scatterplot of 'Time feature')\n",
    "ax2.boxplot(data['Amount'])\n",
    "ax2.set_xlabel('Amount')\n",
    "ax2.set_title('Boxplot of 'Amount' feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling 'Time' and 'Amount'\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scaler = StandardScaler()\n",
    "\n",
    "data['scaled_amount'] = std_scaler.fit_transform(data['Amount'].values.reshape(-1,1))\n",
    "data['scaled_time'] = std_scaler.fit_transform(data['Time'].values.reshape(-1,1))\n",
    "\n",
    "data.drop(['Time','Amount'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model using XGBClassifier, using common test_train_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.999445\n",
      "As 99.828% of the data is class 0, the 99.945% heavily biased accuracy does not tell us much about the quality of our model .\n",
      "f1 score is a better metric: 0.840404\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(data.drop('Class', axis=1), data.Class, \n",
    "                                                   test_size=0.5, random_state=123)\n",
    "\n",
    "clf = xgb.XGBClassifier(n_estimators=10, seed=123)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy: %f\" % (accuracy))\n",
    "print('As 99.828% of the data is class 0, the 99.945% heavily biased accuracy does not tell us much about the quality of our model .')\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"f1 score is a better metric: %f\" % (f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling & Models : Decreases performance\n",
    "\n",
    "* **OVERSAMPLING OR UNDERSAMPLING SHOULD ONLY BE APPLIED TO TRAIN.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampling : Does extremely bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(data.drop('Class', axis=1), data.Class,\n",
    "                                                   test_size=0.5, random_state=123)\n",
    "\n",
    "y_0=y_train[y_train==0]\n",
    "y_0_under=y_0.sample(n=len(y_1), random_state=123)\n",
    "y_1=y_train[y_train==1]\n",
    "y_under=pd.concat([y_0_under,y_1]).sample(frac=1, random_state=123)\n",
    "X_under=X_train.reindex(y_under.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    235\n",
       "0    235\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target is no longer imbalanced. \n",
    "pd.DataFrame(y_under)['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.059856\n"
     ]
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(n_estimators=10, seed=123)\n",
    "clf.fit(X_under, y_under)\n",
    "y_pred = clf.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"f1 score: %f\" % (f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
       "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
       "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'scaled_amount',\n",
       "       'scaled_time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Oversampling : Reduces f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Orpita Das\\Documents\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning:\n",
      "\n",
      "Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(data.drop('Class', axis=1), data.Class,\n",
    "                                                   test_size=0.5, random_state=123)\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "method = RandomOverSampler()\n",
    "X_over, y_over = method.fit_resample(X_train,y_train)\n",
    "X_over = pd.DataFrame(X_over, columns=['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
    "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
    "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'scaled_amount',\n",
    "       'scaled_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    142168\n",
       "0    142168\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target is no longer imbalanced. \n",
    "pd.DataFrame(y_over)[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.585635\n"
     ]
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(n_estimators=10, seed=123)\n",
    "clf.fit(X_over, y_over)\n",
    "y_pred = clf.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"f1 score: %f\" % (f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synthetic Minority Oversampling: f1_score is even worse. \n",
    "\n",
    "* SMOTE is an improved version of Random Oversampling. But this is useful only when all undersampled cases are similar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(data.drop('Class', axis=1), data.Class,\n",
    "                                                   test_size=0.5, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Orpita Das\\Documents\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning:\n",
      "\n",
      "Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "method = SMOTE()\n",
    "X_over, y_over = method.fit_resample(X_train,y_train)\n",
    "X_over = pd.DataFrame(X_over, columns=['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
    "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
    "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'scaled_amount',\n",
    "       'scaled_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    142168\n",
       "0    142168\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target is no longer imbalanced. \n",
    "pd.DataFrame(y_over)[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.282193\n"
     ]
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(n_estimators=10, seed=123)\n",
    "clf.fit(X_over, y_over)\n",
    "y_pred = clf.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"f1 score: %f\" % (f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla XGBoostClassifier does significantly better on unaltered data. Under/oversampling techniques decrease performance. \n",
    "\n",
    "* This is an interesting result. \n",
    "\n",
    "* Random Forests and Bagging Ensemble methods are commonly used for imbalanced class data. Autoencoder Neural Network work very well to model imbalanced classes. \n",
    "\n",
    "* It will be interesting to see how an Autoencode compares to XGBoostClassifier. \n",
    "\n",
    "* But first, let's improve XGBoostClassifier through hyperparameter tuning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using hyperopt for XGBoostClassifier hyperparameter tuning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Parameter spaces can be built from manually entering values or selecting from one of these distrbutions.\n",
    "    - hp.choice(label, options) — Returns one of the options, which should be a list or tuple.\n",
    "    - hp.randint(label, upper) — Returns a random integer between the range (0, upper).\n",
    "    - hp.uniform(label, low, high) — Returns a value uniformly between low and high.\n",
    "    - hp.quniform(label, low, high, q) — Returns a value round(uniform(low, high) / q) * q, i.e it rounds the decimal values and returns an integer\n",
    "    - hp.normal(label, mean, std) — Returns a real value that’s normally-distributed with mean and standard deviation sigma.\n",
    "    \n",
    "    \n",
    "* The function optimized by hyperopt always minimizes - so we have to return 1-f1_score, in order to maximize this metric of our choice. \n",
    "\n",
    "\n",
    "* An odd feature: parameter names have to be provided twice in the parameter selection space. \n",
    "\n",
    "\n",
    "* XGBoost uses a special matrix type called a DMatrix. xgb.XGBClassifier automatically groups the data in a DMatrix, but when using cross validation or more complicated code, we must explicitly convert data to a DMatrix first. \n",
    "\n",
    "\n",
    "* the Trials() function stores data as the hyperopt algorithm progresses. It allows us to learn a few details about the internal working of the hyperopt algorithm. Running the Trials() function is optional. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the space for hyperparameter tuning\n",
    "space={'max_depth': hp.quniform(\"max_depth\", 3, 18, 1),'gamma': hp.uniform ('gamma', 1,9),\n",
    "       'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n",
    "       'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n",
    "       'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "       'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "       'n_estimators': 180}\n",
    "\n",
    "def hyperparameter_tuning(space):\n",
    "    clf=xgb.XGBClassifier(n_estimators =space['n_estimators'], max_depth = int(space['max_depth']), gamma = space['gamma'],\n",
    "                         reg_alpha = int(space['reg_alpha']),min_child_weight=space['min_child_weight'],\n",
    "                         colsample_bytree=space['colsample_bytree'], nthread=-1)\n",
    "    evaluation = [( X_train, y_train), ( X_test, y_test)]\n",
    "    \n",
    "    clf.fit(X_train, y_train,\n",
    "            eval_set=evaluation, eval_metric=\"rmse\",\n",
    "            early_stopping_rounds=10,verbose=False)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print (\"F1 SCORE:\", f1)\n",
    "    #change the metric if you like\n",
    "    return {'loss': 1-f1, 'status': STATUS_OK }\n",
    "\n",
    "\n",
    "# run the hyper paramter tuning\n",
    "trials = Trials()\n",
    "\n",
    "best = fmin(fn=hyperparameter_tuning,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=100)\n",
    "\n",
    "print (best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best model from hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'colsample_bytree': 0.5653326096522678,\n",
    " 'gamma': 1.6283396367528893,\n",
    " 'max_depth': 4,\n",
    " 'min_child_weight': 0.0,\n",
    " 'reg_alpha': 55,\n",
    " 'reg_lambda': 0.26983029795530716}\n",
    "clf=xgb.XGBClassifier(**params)\n",
    "evaluation = [( X_train, y_train), ( X_test, y_test)]\n",
    "clf.fit(X_train, y_train, eval_set=evaluation, eval_metric=\"rmse\", early_stopping_rounds=10,verbose=False)\n",
    "y_pred = clf.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "f1=f1_score(y_test,y_pred)\n",
    "print(f1) #nthreads- for multicore"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "284.444px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
